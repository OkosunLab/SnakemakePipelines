####################################################################
##
## Snakefile for the alignment and counting of RNAseq fastq files
##
## Written by: Findlay Bewicke-Copley
## Date: 02/10/2025
####################################################################

import glob
import re

## Load config file
configfile: "RNAseq.alignment.counting.yaml"
## Load Sample Sheet
sampleFile = open(config["SampleSheet"]).readlines()
## Take the first line as a header
header = sampleFile.pop(0).rstrip().split("\t")
## Generate sample dictionary
sampleSheet = {}
## Run through the sample file and create a dictionary
for line in sampleFile:
		## Remove whitespace and split on tabs
		line = line.rstrip().split("\t")
		## zip the line info (values) and the header (keys) to generate a dictionary
		rv = dict(zip(header, line))
		## if the sample name isn't in the dictionary keys:
		if not rv["sample"] in sampleSheet.keys():
				## Add it and attach the dictionary
				## N.B. "sample" needs to be unique
				sampleSheet[rv["sample"]] = rv
		## If there are multiple samples
		else:
				## Raise and error and complain about it.
				raise Exception("Sorry, please make sure the sample column is unique")
## set the value of SAMPLES to sampleSheet.keys()
## This could be replaced throughout the file BUT SAMPLES is easier to type ....
SAMPLES = sampleSheet.keys()

READS = ["R1","R2"]

#########################################################
## Functions
##########################################################

## Find all FASTQ files of a specific read given the sample ID

def get_R1(wildcards):
	files = glob.glob('{}/{}_*R1*.fastq.gz'.format(config["rawFolder"], wildcards.sample))
	files.sort()
	return files

def get_R2(wildcards):
	files = glob.glob('{}/{}_*R2*.fastq.gz'.format(config["rawFolder"], wildcards.sample))
	files.sort()
	return files

## Find all FASTQ files given the sample ID and read ID

def get_fastq_from_sample_read(wildcards):
	files = glob.glob('FASTQ_Raw/Combined/{}_*{}*.fastq.gz'.format(wildcards.sample, wildcards.read))
	return files


##########################################################
## RULES
##########################################################

## One rule to run them all

rule multiQC:
	input:
		html=expand("QC/fastp/{sample}.html", sample = SAMPLES),
		txt=expand("QC/fastq_screen/{sample}.{read}.fastq_screen.txt", sample = SAMPLES, read = READS),
		bams=expand("Alignment/{sample}.twopassAligned.sortedByCoord.out.bam", sample =  SAMPLES),
		final=expand("QC/STAR/{sample}.twopassLog.final.out", sample =  SAMPLES),
		log=expand("QC/STAR/{sample}.twopassLog.out", sample =  SAMPLES),
		progress=expand("QC/STAR/{sample}.twopassLog.progress.out", sample =  SAMPLES),
	output:
		"QC/MultiQC/multiqc_report.html",
	conda:
		"envs/multiqc.yaml"
	params:
		mem = config["multiqcMem"],
		time = config["multiqcTime"],
	log:
		"logs/multiqc/multiqc.log",
	threads: 
		config["multiqcThreads"]
	shell:
		"""
		multiqc -o QC/MultiQC/ \
			-n multiqc_report \
			QC RSEM
		"""

##########################################################
## QC and file manuipulation
##########################################################

## If samples are across multiple lanes this will combine them
## If not it will just copy the files into FASTQ_Raw/Combined
## These will be temporary files
## the combined files will be removed after use
rule combine_fastqs:
	input:
		R1 = get_R1,
		R2 = get_R2,
	output:
		R1_out=temp("FASTQ_Raw/Combined/{sample}.R1.combined.fastq.gz"),
		R2_out=temp("FASTQ_Raw/Combined/{sample}.R2.combined.fastq.gz"),
	params:
		mem=config["combineMem"],
		time=config["combineTime"],
	log:
		"logs/combine_fastq/{sample}.log"
	threads: 
		config["combineThreads"] 
	shell:
		"""
		cat {input.R1} > {output.R1_out}
		cat {input.R2} > {output.R2_out}
		"""

## FASTQ screen does a little alignment with a small number of reads from numerous genomes
## tests for contaminants

rule fastq_screen:
	input: 
		"FASTQ_Raw/Combined/{sample}.{read}.combined.fastq.gz"
	output:
		txt="QC/fastq_screen/{sample}.{read}.fastq_screen.txt",
		png="QC/fastq_screen/{sample}.{read}.fastq_screen.png"
	params:
		fastq_screen_config="/data/BCI-OkosunLab/Ref/FASTQ_Screen/fastq_screen.conf",
		subset=100000,
		aligner='bowtie2',
		mem=config["fastqScreenMem"],
		time=config["fastqScreenTime"],
	threads: 
		config["fastqScreenThreads"]
	log:
		"logs/fastq_screen/{sample}.{read}.log"
	wrapper:
		## the up to date version of this wrapper is blacklisted as it doesn't generate the png
		"v3.10.2/bio/fastq_screen"

## FASTP is a tool for QC and trimming of FASTQ files.

rule fastp:
	input:
		sample=["FASTQ_Raw/Combined/{sample}.R1.combined.fastq.gz", "FASTQ_Raw/Combined/{sample}.R2.combined.fastq.gz"]
	output:
		trimmed=[temp("FASTQ_fastp/{sample}.1.fastq.gz"), temp("FASTQ_fastp/{sample}.2.fastq.gz")],
		# Unpaired reads separately
		unpaired1=temp("FASTQ_fastp/{sample}.u1.fastq.gz"),
		unpaired2=temp("FASTQ_fastp/{sample}.u2.fastq.gz"),
		failed=temp("FASTQ_fastp/{sample}.failed.fastq.gz"),
		html="QC/fastp/{sample}.html",
		json="QC/fastp/{sample}.json"
	log:
		"logs/fastp/pe/{sample}.log"
	params:
		extra="-g --detect_adapter_for_pe",
		mem=config["fastpMem"],
		time=config["fastpTime"],
	threads: 
		config["fastpThreads"] 
	wrapper:
		"v4.0.0/bio/fastp"

##########################################################
## Alignment
##########################################################

## Generate STAR index
rule star_index:
	input:
		reference=config["reference"],
		gtf=config["gtf"]
	output:
		index=directory(config["index"])
	threads:
		config["starIdxThreads"]
	conda:
		"envs/STAR.yaml"
	params:
		mem=config["starIdxMem"],
		overhang=config["overhang"]
	log:
		"logs/star_index/index.log"
	shell:
		"""
		STAR --runThreadN {threads} \
			--runMode genomeGenerate \
			--genomeDir {output.index} \
			--genomeFastaFiles {input.reference} \
			--sjdbGTFfile {input.gtf} \
			--sjdbOverhang {params.overhang}
		"""

## Align and sort
rule star:
	input:
		R1="FASTQ_fastp/{sample}.1.fastq.gz",
		R2="FASTQ_fastp/{sample}.2.fastq.gz",
		index=config["index"]
	output:
		bam="Alignment/{sample}.twopassAligned.sortedByCoord.out.bam",
		## Logs
		final="Alignment/{sample}.twopassLog.final.out",
		log="Alignment/{sample}.twopassLog.out",
		progress="Alignment/{sample}.twopassLog.progress.out",
		## Data
		SJ="Alignment/{sample}.twopassSJ.out.tab",
		counts="Alignment/{sample}.twopassReadsPerGene.out.tab",
		## Processing
		genome=temp(directory("Alignment/{sample}.twopass_STARgenome")),
		firstpass=temp(directory("Alignment/{sample}.twopass_STARpass1")),
	log:
		"logs/star_pe/{sample}.log",
	conda:
		"envs/STAR.yaml"
	params:
		# optional parameters
		extra="",
		mem=config["starMem"],
		prefix="Alignment/{sample}.twopass"
	threads: config["starThreads"]
	shell:
		"""
		time STAR --runMode alignReads \
				--twopassMode Basic \
				--genomeDir {input.index} \
				--runThreadN {threads} \
				--readFilesIn {input.R1} {input.R2} \
				--readFilesCommand zcat \
				--outFileNamePrefix {params.prefix} \
				--outSAMtype BAM SortedByCoordinate \
				--outSAMunmapped Within \
				--outSAMattributes Standard \
			--quantMode GeneCounts
		"""

rule cleanup_files:
	input:
		## Logs
		final="Alignment/{sample}.twopassLog.final.out",
		log="Alignment/{sample}.twopassLog.out",
		progress="Alignment/{sample}.twopassLog.progress.out",
		## Data
		SJ="Alignment/{sample}.twopassSJ.out.tab",
		counts="Alignment/{sample}.twopassReadsPerGene.out.tab",
	output:
		## Logs
		final="QC/STAR/{sample}.twopassLog.final.out",
		log="QC/STAR/{sample}.twopassLog.out",
		progress="QC/STAR/{sample}.twopassLog.progress.out",
		## Data
		SJ="Junctions/{sample}.twopassSJ.out.tab",
		counts="Expression/STAR/{sample}.twopassReadsPerGene.out.tab",
	threads: 1
	params:
		mem="1G",
		time="1:0:00"
	shell:
		"""
		mv {input.final} {output.final}
		mv {input.log} {output.log}
		mv {input.progress} {output.progress}
		mv {input.SJ} {output.SJ}
		mv {input.counts} {output.counts}
		"""


##########################################################
## Isoform aware 
##########################################################


#rule rsem_prepare_reference:
#	input:
#		reference_genome=config["reference"],
#	output:
#		multiext(config["rsemPre"],
#			".grp",
#			".ti",
#			".transcripts.fa",
#			".idx.fa",
#			".n2g.idx.fa"),
#		seq="{}.seq".format(config["rsemPre"]),
#	params:
#		extra="--gtf {}".format(config["gtf"]),
#		mem=config["rsemPrepMem"],
#		time=config["rsemPrepTime"]
#	threads:
#		config["rsemPrepThreads"]
#	log:
#		"logs/rsem/prepare-reference.log",
#	wrapper:
#		"v7.6.1/bio/rsem/prepare-reference"
#
#rule rsem_calculate_expression:
#	input:
#		bam="Alignment/{sample}.twopassAligned.sortedByCoord.out.bam",
#		reference=multiext(config["rsemPre"],
#			".grp", 
#			".ti", 
#			".transcripts.fa", 
#			".seq", 
#			".idx.fa", 
#			".n2g.idx.fa"),
#	output:
#		genes_results="RSEM/{sample}.genes.results",
#		isoforms_results="RSEM/{sample}.isoforms.results",
#	params:
#		paired_end=True,
#		extra="",
#		mem=config["rsemRunMem"],
#		time=config["rsemRunTime"],
#	log:
#		"logs/rsem/calculate_expression/{sample}.log",
#	threads: 
#		config["rsemRunThreads"]
#	wrapper:
#		"v7.6.1/bio/rsem/calculate-expression"
