##########################################################
##
## Snakefile for the processing of UMI based DNA seq
##
## Written by: Findlay Bewicke-Copley
## Date: 13-05-2024
##########################################################

import glob
import re

## Load config file
configfile: "Alignment.With.UMI.Collapsing.yaml"
## Used for FASTQC
READS=["R1", "R2"]
READS2=["1", "2"]

## Load Sample Sheet
sampleFile = open(config["SampleSheet"]).readlines()
## Take the first line as a header
header = sampleFile.pop(0).rstrip().split("\t")
## Generate sample dictionary
sampleSheet = {}
## Run through the sample file and create a dictionary
for line in sampleFile:
        ## Remove whitespace and split on tabs
        line = line.rstrip().split("\t")
        ## zip the line info (values) and the header (keys) to generate a dictionary
        rv = dict(zip(header, line))
        ## if the sample name isn't in the dictionary keys:
        if not rv["sample"] in sampleSheet.keys():
                ## Add it and attach the dictionary
                ## N.B. "sample" needs to be unique
                sampleSheet[rv["sample"]] = rv
        ## If there are multiple samples
        else:
                ## Raise and error and complain about it.
                raise Exception("Sorry, please make sure the sample column is unique")
## set the value of SAMPLES to sampleSheet.keys()
## This could be replaced throughout the file BUT SAMPLES is easier to type ....
SAMPLES = sampleSheet.keys()

## print(SAMPLES)
##########################################################
## Functions
##########################################################

## Find all FASTQ files of a specific read given the sample ID

def get_R1(wildcards):
	files = glob.glob('{}/{}_*R1*.fastq.gz'.format(config["rawFolder"], wildcards.sample))
	files.sort()
	return files

def get_R2(wildcards):
	files = glob.glob('{}/{}_*R3*.fastq.gz'.format(config["rawFolder"], wildcards.sample))
	files.sort()
	return files

def get_UMI(wildcards):
	files = glob.glob('{}/{}_*R2*.fastq.gz'.format(config["rawFolder"], wildcards.sample))
	files.sort()
	return files
 
## Find all FASTQ files given the sample ID and read ID

def get_fastq_from_sample_read(wildcards):
	files = glob.glob('FASTQ_Raw/Combined/{}_*{}*.fastq.gz'.format(wildcards.sample, wildcards.read))
	return files

##########################################################
## RULES
##########################################################

## One rule to run them all

rule multiQC:
	input:
		picard=expand("QC/depth/picard/{sample}.txt", sample = SAMPLES),		
		html=expand("QC/fastp/{sample}.html", sample = SAMPLES),
		rawBam=expand("QC/samtools_stats/{sample}.raw.txt", sample = SAMPLES),
		conBam=expand("QC/samtools_stats/{sample}.con.txt", sample = SAMPLES),
		UMIQC=expand("QC/fgbio/{sample}.family_size_histogram.txt", sample = SAMPLES),
		txt=expand("QC/fastq_screen/{sample}.{read}.fastq_screen.txt", sample = SAMPLES, read = READS),
	output:
		"QC/MultiQC/multiqc_report.html",
	conda:
		"envs/multiqc.yaml"
	params:
		mem = config["multiqcMem"]
	resources:
		mem_mb_per_cpu = config["multiqcMemMB"],
		runtime = config["multiqcTime"],
	log:
		"logs/multiqc/multiqc.log",
	threads: 
		config["multiqcThreads"]
	shell:
		"""
		multiqc -o QC/MultiQC/ \
			-n multiqc_report \
			-f QC
		"""

##########################################################
## QC and file manuipulation
##########################################################

## If samples are across multiple lanes this will combine them
## If not it will just copy the files into FASTQ_Raw/Combined
## These will be temporary files
## the combined files will be removed after use
rule combine_fastqs:
	input:
		R1 = get_R1,
		R2 = get_R2,
		UMI = get_UMI
	output:
		R1_out=temp("FASTQ_Raw/Combined/{sample}.R1.combined.fastq.gz"),
		R2_out=temp("FASTQ_Raw/Combined/{sample}.R2.combined.fastq.gz"),
		UMI_out=temp("FASTQ_Raw/Combined/{sample}.UMI.combined.fastq.gz")
	params:
		mem=config["combineMem"],
	resources:
		mem_mb_per_cpu = config["combineMemMB"],
		runtime = config["combineTime"],
	log:
		"logs/combine_fastq/{sample}.log"
	threads: 
		config["combineThreads"]
	shell:
		"""
		cat {input.R1} > {output.R1_out}
		cat {input.R2} > {output.R2_out}
		cat {input.UMI} > {output.UMI_out} 
		"""

## FASTQ screen does a little alignment with a small number of reads from numerous genomes
## tests for contaminants

rule fastq_screen:
	input: 
		"FASTQ_Raw/Combined/{sample}.{read}.combined.fastq.gz"
	output:
		txt="QC/fastq_screen/{sample}.{read}.fastq_screen.txt",
		png="QC/fastq_screen/{sample}.{read}.fastq_screen.png"
	params:
		fastq_screen_config="/data/BCI-OkosunLab/Ref/FASTQ_Screen/fastq_screen.conf",
		subset=100000,
		aligner='bowtie2',
		mem=config["fastqScreenMem"],
	resources:
		mem_mb_per_cpu = config["fastqScreenMemMB"],
		runtime = config["fastqScreenTime"],
	threads: config["fastqScreenThreads"]
	log:
		"logs/fastq_screen/{sample}.{read}.log"
	wrapper:
		## the up to date version of this wrapper is blacklisted as it doesn't generate the png
		"v3.10.2/bio/fastq_screen"

## FASTP is a tool for QC and trimming of FASTQ files.
rule fastp:
	input:
		sample=["FASTQ_Raw/Combined/{sample}.R1.combined.fastq.gz", "FASTQ_Raw/Combined/{sample}.R2.combined.fastq.gz"]
	output:
		trimmed=["FASTQ_fastp/{sample}.1.fastq.gz", "FASTQ_fastp/{sample}.2.fastq.gz"],
		# Unpaired reads separately
		unpaired1="FASTQ_fastp/{sample}.u1.fastq.gz",
		unpaired2="FASTQ_fastp/{sample}.u2.fastq.gz",
		failed="FASTQ_fastp/{sample}.failed.fastq.gz",
		html="QC/fastp/{sample}.html",
		json="QC/fastp/{sample}.json"
	log:
		"logs/fastp/pe/{sample}.log"
	params:
		## detect adapter for pe should work out what the adapters are.
		extra="-g --detect_adapter_for_pe",
		mem=config["fastpMem"]
	resources:
		mem_mb_per_cpu = config["fastpMemMB"],
		runtime = config["fastpTime"],
	threads: 
		config["fastpThreads"]
	wrapper:
		"v4.0.0/bio/fastp"


##########################################################
## Alignment
##########################################################

rule bwa_mem:
	input:
		R1="FASTQ_fastp/{sample}.1.fastq.gz",
		R2="FASTQ_fastp/{sample}.2.fastq.gz",
		idx=config["bwa_index"],
	output:
		temp("Alignment/{sample}.raw.bam")
	log:
		"logs/bwa_mem/{sample}.log",
	params:
		extra=r"-R '@RG\tID:{sample}\tSM:{sample}\tPL:Illumina'",
		sorting="samtools",  # Can be 'none', 'samtools' or 'picard'.
		sort_order="coordinate",  # Can be 'queryname' or 'coordinate'.
		sort_extra="",  # Extra args for samtools/picard.
		mem=config["bwaMem"],
	resources:
		mem_mb_per_cpu = config["bwaMemMB"],
		runtime = config["bwaTime"],
	threads: 
		config["bwaThreads"]
	conda:
		"envs/bwa.yaml"
	shell:
		"""
		bwa mem -t {threads} -M {input.idx} \
			{params.extra} \
			{input.R1} {input.R2} |
			samtools view -Sbh - > {output}
		"""

## Alignment QC

rule samtools_stats_raw:
	input:
		bam="Alignment/{sample}.raw.bam"
	output:
		"QC/samtools_stats/{sample}.raw.txt",
	params:
		extra="",  # Optional: extra arguments.
		mem=config["samtoolsStatMem"]
	resources:
		mem_mb_per_cpu = config["samtoolsStatMemMB"],
		runtime = config["samtoolsStatTime"],
	threads: 
		config["samtoolsStatThreads"]
	log:
		"logs/samtools_stats/{sample}.log",
	wrapper:
		"v4.0.0/bio/samtools/stats"

##########################################################
## FGBIO UMI section
##########################################################

rule annotate_bam:
	input:
		bam="Alignment/{sample}.raw.bam",
		umi="FASTQ_Raw/Combined/{sample}.UMI.combined.fastq.gz",
	output:
		temp("Alignment/{sample}.fg.bam"),
	log:
		"logs/fgbio/annotate_bam/{sample}.log",
	params:
		mem=config["fgbioMem"],
		javaMem=config["fgbioJavaMem"],
	resources:
		mem_mb_per_cpu = config["fgbioMemMB"],
		runtime = config["fgbioTime"],
	threads:
		config["fgbioThreads"]
	conda:
		"envs/fgbio.yaml",
	shell:
		"""
		fgbio {params.javaMem} -XX:+AggressiveOpts -XX:+AggressiveHeap AnnotateBamWithUmis \
			-i {input.bam} \
			-f {input.umi} \
			-o {output}
		"""

rule sort_UMI_bam:
	input:
		"Alignment/{sample}.fg.bam"
	output:
		temp("Alignment/{sample}.fgsort.bam"),
	log:
		"logs/fgbio/sort_bam/{sample}.log",
	params:
		mem=config["fgbioMem"],
		javaMem = config["fgbioJavaMem"]
	resources:
		mem_mb_per_cpu = config["fgbioMemMB"],
		runtime = config["fgbioTime"],
	conda:
		"envs/fgbio.yaml"
	threads: 
		config["fgbioThreads"]
	shell:
		"""
		fgbio {params.javaMem} -XX:+AggressiveOpts -XX:+AggressiveHeap SortBam \
			-i {input} \
			-s Queryname \
			-o {output}
		"""

rule set_mate_info:
	input:
		"Alignment/{sample}.fgsort.bam"
	output:
		temp("Alignment/{sample}.fgmate.bam")
	log:
		"logs/fgbio/set_mate/{sample}.log"
	conda:
		"envs/fgbio.yaml"
	params:
		mem=config["fgbioMem"],
		javaMem = config["fgbioJavaMem"]
	resources:
		mem_mb_per_cpu = config["fgbioMemMB"],
		runtime = config["fgbioTime"],
	threads:
		config["fgbioThreads"]
	shell:
		"""
		fgbio {params.javaMem} -XX:+AggressiveOpts -XX:+AggressiveHeap SetMateInformation \
			-i {input} \
			-o {output}
		"""

rule group_reads:
	input:
		"Alignment/{sample}.fgmate.bam"
	output:
		bam=temp("Alignment/{sample}.fggrp.bam"),
		qc="QC/fgbio/{sample}.family_size_histogram.txt"
	log:
		"logs/fgbio/group_reads/{sample}.log"
	params:
		mem=config["fgbioMem"],
		javaMem = config["fgbioJavaMem"]
	resources:
		mem_mb_per_cpu = config["fgbioMemMB"],
		runtime = config["fgbioTime"],
	conda:
		"envs/fgbio.yaml"
	threads:
		config["fgbioThreads"]
	shell:
		"""
		fgbio {params.javaMem} -XX:+AggressiveOpts -XX:+AggressiveHeap GroupReadsByUmi \
			-i {input} \
			-f {output.qc} \
			-s adjacency \
			-o {output.bam}
		"""

rule call_consensus:
	input:
		"Alignment/{sample}.fggrp.bam"
	output:
		temp("Alignment/{sample}.fgcon.bam")
	log:
		"logs/fgbio/call_consensus/{sample}.log"
	conda:
		"envs/fgbio.yaml"
	params:
		mem=config["fgbioMem"],
		javaMem = config["fgbioJavaMem"],
		consensusReads = config["consensusReads"],
	resources:
		mem_mb_per_cpu = config["fgbioMemMB"],
		runtime = config["fgbioTime"],
	threads: 
		config["fgbioThreads"]
	shell:
		"""
		fgbio {params.javaMem} -XX:+AggressiveOpts -XX:+AggressiveHeap CallMolecularConsensusReads \
			-i {input} \
			-o {output} \
			-M 1
		"""

##########################################################
## Consensus Construction
##########################################################

rule consensus_fastq:
	input:
		"Alignment/{sample}.fgcon.bam"
	output:
		R1="FASTQ_Con/{sample}.con.R1.fastq.gz",
		R2="FASTQ_Con/{sample}.con.R2.fastq.gz"
	log:
		"logs/samtools/separate/{sample}.separate.log",
	params:
		sort="-m 4G",
		fastq="-n",
		mem=config["consensusFastqMem"],
	resources:
		mem_mb_per_cpu = config["consensusFastqMemMB"],
		runtime = config["consensusFastqTime"],
	## Remember, this is the number of samtools' additional threads. 
	## At least 2 threads have to be requested on cluster sumbission. 
	## This value - 2 will be sent to samtools sort -@ argument.
	threads: 
		config["consensusFastqThreads"]
	wrapper:
		"v4.0.0/bio/samtools/fastq/separate"

rule bwa_mem_consensus:
	input:
		R1="FASTQ_Con/{sample}.con.R1.fastq.gz",
		R2="FASTQ_Con/{sample}.con.R2.fastq.gz",
		idx=config["bwa_index"]
	output:
		"Alignment/{sample}.con.bam"
	log:
		"logs/bwa_mem_consensus/{sample}.log",
	params:
		extra=r"-R '@RG\tID:{sample}\tSM:{sample}\tPL:Illumina'",
		sorting="samtools",  # Can be 'none', 'samtools' or 'picard'.
		sort_order="coordinate",  # Can be 'queryname' or 'coordinate'.
		sort_extra="",  # Extra args for samtools/picard.
		mem=config["bwaMem"],
	resources:
		mem_mb_per_cpu = config["bwaMemMB"],
		runtime = config["bwaTime"],
	threads: 
		config["bwaThreads"]
	conda:
		"envs/bwa.yaml"
	shell:
		"""
		bwa mem -t {threads} -M {input.idx} \
			{params.extra} \
			{input.R1} {input.R2} |
			samtools sort -@{threads} -o {output} -
		"""

rule samtools_index:
	input:
		"Alignment/{sample}.con.bam"
	output:
		"Alignment/{sample}.con.bai",
	log:
		"logs/samtools_index/{sample}.log",
	params:
		extra="",  # optional params string
		mem=config["samtoolsIdxMem"]
	resources:
		mem_mb_per_cpu = config["samtoolsIdxMemMB"],
		runtime = config["samtoolsIdxTime"],
	threads: 
		config["samtoolsIdxThreads"]# This value - 1 will be sent to -@
	wrapper:
		"v4.0.0/bio/samtools/index"
	

##########################################################
## Bam file stats
##########################################################

rule samtools_stats_con:
	input:
		bam="Alignment/{sample}.con.bam"
	output:
		"QC/samtools_stats/{sample}.con.txt",
	params:
		extra="",  # Optional: extra arguments.
		mem=config["samtoolsStatMem"]
	resources:
		mem_mb_per_cpu = config["samtoolsStatMemMB"],
		runtime = config["samtoolsStatTime"],
	threads: 
		config["samtoolsStatThreads"]
	log:
		"logs/samtools_stats/{sample}.con.log",
	wrapper:
		"v4.0.0/bio/samtools/stats"

rule gatk_depth_of_coverage:
	input:
		bam="Alignment/{sample}.con.bam",
		fasta=config["reference"],
		intervals=config["intervals"],
		idx="Alignment/{sample}.con.bai"
	output:
		multiext(
			"QC/depth/{sample}",
			".sample_interval_summary",
			".sample_cumulative_coverage_counts",
			".sample_cumulative_coverage_proportions",
			".sample_interval_statistics",
			".sample_statistics",
			".sample_summary",
			)
	log:
		"logs/gatk/depthofcoverage/{sample}.log",
	params:
		extra="--omit-depth-output-at-each-base true",
		java_opts="",
		out=lambda w: "QC/depth/{}".format(w.sample),
		mem=config["gatkMem"]
	resources:
		mem_mb=config["gatkRunMem"],
		mem_mb_per_cpu = config["gatkMemMB"],
		runtime = config["gatkTime"],
	threads:
		config["gatkThreads"]
	conda:
		"envs/gatk4.yaml"
	shell:
		"""
		gatk DepthOfCoverage \
			-R {input.fasta} \
			-O {params.out} \
			-I {input.bam} \
			-L {input.intervals} \
			{params.extra}
		"""

rule bed_to_interval_list:
	input:
		bed=config["intervals"],
			dict=config["dict"],
	output:
		temp("QC/picard.interval_list"),
	log:
		"logs/picard/bedtointervallist/Log.log",
	threads:
		config["picardThreads"]
	params:
		# optional parameters
		extra="--SORT true",  # sort output interval list before writing
		mem=config["picardMem"]
	resources:
		mem_mb_per_cpu = config["picardMemMB"],
		runtime = config["picardTime"],
	wrapper:
		"v4.0.0/bio/picard/bedtointervallist"

rule picard_collect_hs_metrics:
	input:
		bam="Alignment/{sample}.con.bam",
		bai="Alignment/{sample}.con.bai",
		reference=config["reference"],
		# Baits and targets should be given as interval lists. These can
		# be generated from bed files using picard BedToIntervalList.
		target_intervals="QC/picard.interval_list",
	output:
		"QC/depth/picard/{sample}.txt",
	params:
		# Optional extra arguments. Here we reduce sample size
		# to reduce the runtime in our unit test.
		extra="",
		mem=config["picardMem"]
	resources:
		mem_mb_per_cpu = config["picardMemMB"],
		runtime = config["picardTime"],
	threads:
		config["picardThreads"]
	log:
		"logs/picard_collect_hs_metrics/{sample}.log",
	conda:
		"envs/gatk4.yaml"
	shell:
		"""
		gatk CollectHsMetrics \
			-R {input.reference} \
			-O {output} \
			-I {input.bam} \
			-TI {input.target_intervals} \
			-BI {input.target_intervals}
			{params.extra}
		"""
